{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# understanding pooling and padding in CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling in CNNs\n",
    "\n",
    "**Purpose**: Pooling is a down-sampling operation used in CNNs to reduce the spatial dimensions (width and height) of the input feature maps. It helps to decrease the computational complexity and control overfitting by summarizing the most important information while retaining the spatial hierarchies.\n",
    "\n",
    "**Benefits**:\n",
    "1. **Dimension Reduction**: Pooling reduces the spatial dimensions, making computations faster and more memory-efficient.\n",
    "2. **Translation Invariance**: Pooling makes the network less sensitive to small translations in the input data.\n",
    "3. **Feature Learning**: Pooling helps the network focus on the most salient features while discarding less relevant details.\n",
    "\n",
    "## Max Pooling vs. Average Pooling\n",
    "\n",
    "**Max Pooling**: Max pooling takes the maximum value from a local region of the input feature map. It retains the most prominent features, making it effective for capturing strong activations.\n",
    "\n",
    "**Average Pooling**: Average pooling calculates the average value of the local region. It provides a smoother summary of the input and is less sensitive to outliers.\n",
    "\n",
    "## Padding in CNNs\n",
    "\n",
    "**Concept**: Padding involves adding extra pixels around the border of the input image or feature maps before applying convolution or pooling operations.\n",
    "\n",
    "**Significance**:\n",
    "1. **Preserve Spatial Dimensions**: Padding ensures that the spatial dimensions of the output feature maps after convolution or pooling remain the same as the input dimensions.\n",
    "2. **Prevent Information Loss**: Without padding, applying convolution or pooling operations repeatedly can lead to information loss at the edges of the image.\n",
    "\n",
    "## Zero-padding vs. Valid-padding\n",
    "\n",
    "**Zero-padding**: In zero-padding, extra rows and columns of zeros are added to the border of the input image or feature map. It helps in preserving the spatial dimensions and reduces the information loss.\n",
    "\n",
    "**Valid-padding**: Valid-padding, also known as \"no-padding,\" means no extra pixels are added to the border. It results in a smaller output size compared to the input size.\n",
    "\n",
    "**Impact on Output Size**:\n",
    "- Zero-padding keeps the output size the same as the input size or reduces it slightly, depending on the filter size and stride.\n",
    "- Valid-padding reduces the output size based on the filter size and stride, as it doesn't include the additional border.\n",
    "\n",
    "In summary, pooling helps reduce spatial dimensions while retaining important features, padding preserves spatial dimensions and prevents information loss, and different types of padding affect the output size differently. The choice of pooling and padding techniques depends on the specific architecture, task, and requirements of your CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploring LeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certainly! Here's an overview of the LeNet-5 architecture, its components, advantages, and limitations, along with an example implementation using TensorFlow:\n",
    "\n",
    "## LeNet-5 Overview:\n",
    "\n",
    "LeNet-5 is a classic convolutional neural network architecture designed by Yann LeCun in the 1990s. It was one of the first successful architectures for handwritten digit recognition, and it played a crucial role in shaping modern CNN designs.\n",
    "\n",
    "## Components and Their Purposes:\n",
    "\n",
    "1. **Input Layer**: Accepts grayscale images of size 32x32 pixels.\n",
    "\n",
    "2. **Convolutional Layer (C1)**: Applies convolutional filters to extract local features. It uses 6 filters of size 5x5, followed by ReLU activation.\n",
    "\n",
    "3. **Pooling Layer (S2)**: Performs max-pooling with 2x2 receptive fields to reduce spatial dimensions and create translation invariance.\n",
    "\n",
    "4. **Convolutional Layer (C3)**: Applies convolution to the pooled features, using 16 filters of size 5x5.\n",
    "\n",
    "5. **Pooling Layer (S4)**: Another max-pooling layer with 2x2 receptive fields.\n",
    "\n",
    "6. **Fully Connected Layer (F5)**: A fully connected layer with 120 neurons followed by a ReLU activation.\n",
    "\n",
    "7. **Fully Connected Layer (F6)**: A fully connected layer with 84 neurons, again followed by ReLU activation.\n",
    "\n",
    "8. **Output Layer**: A fully connected layer with 10 neurons for digit classification using softmax activation.\n",
    "\n",
    "## Advantages and Limitations:\n",
    "\n",
    "**Advantages**:\n",
    "- LeNet-5 was groundbreaking in demonstrating the effectiveness of convolutional neural networks for image classification.\n",
    "- It introduced concepts like convolutional and pooling layers, which are foundational to modern CNN architectures.\n",
    "- LeNet-5 paved the way for further research and development in deep learning for image recognition.\n",
    "\n",
    "**Limitations**:\n",
    "- Designed for small 32x32 images, limiting its applicability to larger images.\n",
    "- Limited model capacity compared to modern architectures, which can affect performance on complex tasks.\n",
    "- LeNet-5 doesn't include many advanced techniques that have since been developed, such as more complex activation functions, normalization layers, and skip connections.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Implementation using TensorFlow:\n",
    "\n",
    "Below is a basic example of implementing LeNet-5 using TensorFlow and training it on the MNIST dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-17 16:10:28.788809: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-17 16:10:31.888525: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-17 16:10:31.892598: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-17 16:10:34.610984: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 2s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-17 16:10:44.803286: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 188160000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  7/938 [..............................] - ETA: 20s - loss: 2.2389 - accuracy: 0.1964 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-17 16:10:47.481102: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 23193600 exceeds 10% of free system memory.\n",
      "2023-08-17 16:10:47.481377: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 23193600 exceeds 10% of free system memory.\n",
      "2023-08-17 16:10:47.489607: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 25171200 exceeds 10% of free system memory.\n",
      "2023-08-17 16:10:47.509324: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 23193600 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 24s 24ms/step - loss: 0.2417 - accuracy: 0.9276 - val_loss: 0.0822 - val_accuracy: 0.9743\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 22s 23ms/step - loss: 0.0769 - accuracy: 0.9759 - val_loss: 0.0558 - val_accuracy: 0.9830\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 21s 23ms/step - loss: 0.0557 - accuracy: 0.9825 - val_loss: 0.0428 - val_accuracy: 0.9859\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 21s 23ms/step - loss: 0.0453 - accuracy: 0.9855 - val_loss: 0.0422 - val_accuracy: 0.9877\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 22s 23ms/step - loss: 0.0373 - accuracy: 0.9881 - val_loss: 0.0381 - val_accuracy: 0.9891\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 22s 24ms/step - loss: 0.0311 - accuracy: 0.9897 - val_loss: 0.0510 - val_accuracy: 0.9838\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 21s 22ms/step - loss: 0.0267 - accuracy: 0.9915 - val_loss: 0.0409 - val_accuracy: 0.9870\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 21s 22ms/step - loss: 0.0242 - accuracy: 0.9920 - val_loss: 0.0326 - val_accuracy: 0.9891\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 21s 23ms/step - loss: 0.0205 - accuracy: 0.9930 - val_loss: 0.0424 - val_accuracy: 0.9878\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 22s 24ms/step - loss: 0.0181 - accuracy: 0.9942 - val_loss: 0.0359 - val_accuracy: 0.9893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fb168dee6b0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Load and preprocess the MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Build LeNet-5 architecture\n",
    "model = Sequential([\n",
    "    Conv2D(6, kernel_size=(5, 5), activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(16, kernel_size=(5, 5), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(120, activation='relu'),\n",
    "    Dense(84, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_images.reshape(-1, 28, 28, 1), train_labels, epochs=10, batch_size=64, validation_data=(test_images.reshape(-1, 28, 28, 1), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code creates a simplified version of LeNet-5 using TensorFlow/Keras and trains it on the MNIST dataset. You can modify and expand this code to suit your needs.\n",
    "\n",
    "In summary, LeNet-5 is a foundational CNN architecture that introduced key concepts to the field of deep learning for image classification. While it has limitations compared to modern architectures, it remains an important milestone in the history of deep learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyzing AlexNet "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet Overview:\n",
    "\n",
    "AlexNet is a pioneering deep convolutional neural network (CNN) architecture developed by Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton. It won the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) in 2012 and marked a significant breakthrough in the field of deep learning for image classification.\n",
    "\n",
    "## Architectural Innovations:\n",
    "\n",
    "1. **Deep Architecture**: AlexNet was one of the first CNNs with multiple convolutional and fully connected layers. It demonstrated that deeper networks could learn hierarchical features effectively.\n",
    "\n",
    "2. **ReLU Activation**: AlexNet used the Rectified Linear Unit (ReLU) activation function, which helped mitigate the vanishing gradient problem and accelerated training.\n",
    "\n",
    "3. **Data Augmentation**: The architecture employed data augmentation techniques, such as cropping, flipping, and changing brightness, to increase the diversity of training data and improve generalization.\n",
    "\n",
    "4. **Dropout**: AlexNet introduced dropout regularization during training, which randomly disables neurons to prevent overfitting.\n",
    "\n",
    "5. **Local Response Normalization**: This normalization technique was used to introduce local competition between adjacent neurons and enhance the selectivity of the model.\n",
    "\n",
    "## Architecture Components:\n",
    "\n",
    "1. **Convolutional Layers**: AlexNet consists of five convolutional layers. The first layer used a large 11x11 filter with a stride of 4, followed by smaller filters in subsequent layers. These layers captured features of varying scales and complexities.\n",
    "\n",
    "2. **Pooling Layers**: Three max-pooling layers were used to reduce spatial dimensions and introduce translation invariance. The pooling layers used 3x3 receptive fields with a stride of 2.\n",
    "\n",
    "3. **Fully Connected Layers**: There are three fully connected layers in AlexNet. The first two are followed by dropout regularization to prevent overfitting.\n",
    "\n",
    "## Example Implementation using TensorFlow:\n",
    "\n",
    "Here's a simplified example of implementing AlexNet using TensorFlow/Keras:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(96, kernel_size=(11, 11), strides=4, activation='relu', input_shape=(227, 227, 3)),\n",
    "    MaxPooling2D(pool_size=(3, 3), strides=2),\n",
    "    Conv2D(256, kernel_size=(5, 5), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(3, 3), strides=2),\n",
    "    Conv2D(384, kernel_size=(3, 3), activation='relu'),\n",
    "    Conv2D(384, kernel_size=(3, 3), activation='relu'),\n",
    "    Conv2D(256, kernel_size=(3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(3, 3), strides=2),\n",
    "    Flatten(),\n",
    "    Dense(4096, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(4096, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1000, activation='softmax')  # Assumes 1000-class ImageNet classification\n",
    "])\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Train the model using suitable dataset (e.g., ImageNet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In summary, AlexNet introduced multiple architectural innovations, including deep convolutional layers, ReLU activation, data augmentation, dropout, and local response normalization. It set the foundation for modern CNN architectures and demonstrated the power of deep learning for image classification tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
